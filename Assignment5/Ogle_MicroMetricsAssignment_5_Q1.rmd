---
title: "Assignment 5 Question 1"
author: "Jack Ogle in collaboration with Eva Haque, Matt Lohrs, and Jack Knickrehm"
output:
  pdf_document:
    keep_tex: true
header-includes:
   - \usepackage{dcolumn}
   - \usepackage{float}
classoption: landscape
geometry: margin=1in
fontsize: 12pt
---


```{r, include=FALSE}
# Loading Packages
library(tidyverse)
library(haven)
library(stargazer)
library(tinytex)
library(foreign)
library(multiwayvcov)
library(lmtest)
library(rdrobust)

# Loading Data
damon = read_dta('/Users/matthewogle/micro-metrics/Assignment5/damonclark.dta')

# Generating Dummy for winning and losing
damon$win = ifelse((damon$vote >= 50), 1, 0)
damon$lose = ifelse((damon$vote < 50), 1, 0)

# Generating Margin
damon$margin = damon$vote - 50
damon$margin_sqr = damon$margin^2

# Generating Interactions
win_margin = lm(win ~ margin + margin_sqr, data = damon)
lose_margin = lm(lose ~ margin + margin_sqr, data = damon)

```


(a)

The assumptions underlying the RDD in this paper are that in order for the school to attain autonomy (GM) there must be a 50% vote from the community to have the school be GM. Clark also assumes that the school performance, test scores, is increasing in autonomy and school effort. Schools that are already GM at the start of a period are fully autonomous and therefore decide only how much effort to exert. Effort in turn improves school performance, test scores for example, but effort is costly. Schools that are not GM at the start period must decided how much effort to exert and whether or not to become Gm. For given effort, non GM schools performance is assumed lower than GM school performance; hence schools have an incentive to become GM. There are cost associated with GM status and the decision to become one is non trivial.

The conceptual framework assumed that schools were identical. In practice, schools differ along many dimensions, and certain types of school may be more likely to hold and win a GM vote (e.g., those with more entrepreneurial head teachers). Clark's empirical approach overcomes this selection problem by focusing on the jump in performance among schools at the 50 percent win threshold. Specifically, Clark considers variants of the fuzzy regression discontinuity model for school i voting on GM

(b)

These figures represent figure 8 from the paper. They are all visualizing:

The Impact of GM Status on Schools that Become Grant-Maintained

```{r}
# Restricting Data to (15,85) 
restrict = subset(damon, vote <= 85 & vote >= 15)

# calculating the % change
restrict$percentage_change = restrict$passrate2 - restrict$passrate0

# Base Year
rdplot(y = restrict$passrate0, x = restrict$vote , c = 50, p = 3, nbins = 7, title = "Base Year (bin-width = 7)", x.label= "Vote Share", y.label = "% Pass")

# Base +2 Year
rdplot(y = restrict$passrate2, x = restrict$vote, c = 50, p = 3, nbins = 7, title = "Base + 2 Years (bin-width = 7)", x.label= "Vote Share", y.label = "% Pass")

# % change
rdplot(y = restrict$percentage_change, x = restrict$vote, p = 1, nbins = 7, c = 50, title = "Change (bin-width = 7)", x.label= "Vote Share", y.label = "% Pass")


# Base Year
rdplot(y = restrict$passrate0, x = restrict$vote , c = 50, p = 3, nbins = 2, title = "Base Year (bin-width = 2)", x.label= "Vote Share", y.label = "% Pass")

# Base +2 Year
rdplot(y = restrict$passrate2, x = restrict$vote, c = 50, p = 3, nbins = 2, title = "Base + 2 Years (bin-width = 2)", x.label= "Vote Share", y.label = "% Pass")

# % change
rdplot(y = restrict$percentage_change, x = restrict$vote, p = 1, nbins = 2, c = 50, title = "Change (bin-width = 2)", x.label= "Vote Share", y.label = "% Pass")


```

From the graphs above we can see that as you decrease the bin size from 7 which is what Clark uses in the paper for Figure 8. We can see that there is no difference in terms of the lines of best fit, however, we can better visualize the data with a higher bin width. We see more of the data points.

(c)

Clark restricts his sample to those schools with votes from 15% and 85% because he wants to reduce bias from outliers from schools who were very opposed or very for autonomy. For example schools with high vote shares may have been under threat of closure, whilst few schools received very low vote shares. Additionally, RD necessitates that in order to estimate the average effect of a treatment you look at an arbitrary cutoff and evaluate the treatment effects before and after the cutoff. Additionally they saw that schools outside this interval have different baseline characteristics and are less likely to survive. Clark needs to estimate around the cutoff, 50, which is inside the (15,85) interval. Other columns have functions of vote share because vote share is the forcing variable in this Fuzzy Regression Discontinuity model. Fuzzy RD exploits discontinuities in the probability of treatment conditional on a variate. The discontinuity, here is Vote share, and it becomes the IV for the treatment status. Which is why Table 3a includes functions of vote share both on their own and interacted with the win/lose variable.

(d)

```{r, echo=FALSE}
restrict$vote_share <- restrict$vote/100


model_d_1 <- lm(passrate2 ~ win + vote_share + vote_share*lose + vote_share*win, data = restrict)

model_d_2 <- lm(passrate2 ~ win + vote_share + vote_share*lose + vote_share*win, data = restrict)

model_d_3 <- lm(passrate2 ~ win + vote_share + (vote_share^2)*lose + (vote_share^2)*win, data = restrict)

model_d_4 <- lm(passrate2 ~ win + vote_share + vote_share*lose + vote_share*win + (vote_share^2)*lose + (vote_share^2)*win, data = restrict)


# summary(model_d_1 <- rdrobust(restrict, restrict$win, c = 0.5, all=T))
# Non-Grammar Schools with Vote Shares in [15,85] interval

stargazer(model_d_1, model_d_2, model_d_3, model_d_4, title="Regression Results (d)", align=TRUE, notes = "Standard errors in parentheses", notes.align = "l")

```

\begin{table}[!htbp] \centering 
  \caption{Regression Results (d)} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lD{.}{.}{-3} D{.}{.}{-3} D{.}{.}{-3} D{.}{.}{-3} } 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{4}{c}{\textit{Dependent variable:}} \\ 
\cline{2-5} 
\\[-1.8ex] & \multicolumn{4}{c}{passrate2} \\ 
\\[-1.8ex] & \multicolumn{1}{c}{(1)} & \multicolumn{1}{c}{(2)} & \multicolumn{1}{c}{(3)} & \multicolumn{1}{c}{(4)}\\ 
\hline \\[-1.8ex] 
 win & 14.727^{**} & 14.727^{**} & 14.727^{**} & 14.727^{**} \\ 
  & (7.235) & (7.235) & (7.235) & (7.235) \\ 
  & & & & \\ 
 vote & -0.171^{**} & -0.171^{**} & -0.171^{**} & -0.171^{**} \\ 
  & (0.081) & (0.081) & (0.081) & (0.081) \\ 
  & & & & \\ 
 lose &  &  &  &  \\ 
  &  &  &  &  \\ 
  & & & & \\ 
 vote:lose & 0.249^{*} & 0.249^{*} & 0.249^{*} & 0.249^{*} \\ 
  & (0.147) & (0.147) & (0.147) & (0.147) \\ 
  & & & & \\ 
 win:vote &  &  &  &  \\ 
  &  &  &  &  \\ 
  & & & & \\ 
 Constant & 40.597^{***} & 40.597^{***} & 40.597^{***} & 40.597^{***} \\ 
  & (4.348) & (4.348) & (4.348) & (4.348) \\ 
  & & & & \\ 
\hline \\[-1.8ex] 
Observations & \multicolumn{1}{c}{524} & \multicolumn{1}{c}{524} & \multicolumn{1}{c}{524} & \multicolumn{1}{c}{524} \\ 
R$^{2}$ & \multicolumn{1}{c}{0.009} & \multicolumn{1}{c}{0.009} & \multicolumn{1}{c}{0.009} & \multicolumn{1}{c}{0.009} \\ 
Adjusted R$^{2}$ & \multicolumn{1}{c}{0.004} & \multicolumn{1}{c}{0.004} & \multicolumn{1}{c}{0.004} & \multicolumn{1}{c}{0.004} \\ 
Residual Std. Error (df = 520) & \multicolumn{1}{c}{15.267} & \multicolumn{1}{c}{15.267} & \multicolumn{1}{c}{15.267} & \multicolumn{1}{c}{15.267} \\ 
F Statistic (df = 3; 520) & \multicolumn{1}{c}{1.614} & \multicolumn{1}{c}{1.614} & \multicolumn{1}{c}{1.614} & \multicolumn{1}{c}{1.614} \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{4}{l}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
 & \multicolumn{4}{l}{Standard errors in parentheses} \\ 
\end{tabular} 
\end{table} 

(e)
(f)
(g)
(h)
(i)
(j)